\chapter{Continuous Random Variables}

\section{Probability Density Function}

Recall that a random variable is \bred{continuous} if it can take on values on an interval of real numbers. For example, 

\begin{itemize}
    \item The mass of a randomly selected salmon in kilograms 
    \item The horizontal distance a figure skater travels on a specific type of jump in metres 
    \item The random elapsed time between football plays in seconds
\end{itemize}

\begin{definition}[Probability Density Function]
    The \term{probability density function} (PDF) of a continuous random variable $X$ is a function $f(x)$ that has the following properties.

    \begin{enumerate}
        \item $f(x) \ge 0$ for all $x$ in the support of $X$
        \vspace{0.5em}
        \item $\int_{-\infty}^{\infty} f(x) \,dx = 1$
        \item $P(a \le X \le b) = \int_a^b f(x) \,dx$
    \end{enumerate}
\end{definition}

Note that unlike in the discrete case, the density function $f(x) \neq P(X = x)$ for continuous RV $X$. Instead, $f(x)$ describes the probability \itblue{density} for various values of $x$ and the \bred{area under the probability density function} corresponds to the \bred{probability over the interval}.

\begin{example}
    Verify that $f(y) = 3(y - 1)^2$, $0 \le y \le 1$\footnote{This is called the \term{support}\index{Support (of RV)} of the random variable $Y$ -- the set of $y$ that has \bred{non-zero} probabilities. In other words, $f(y) = \begin{cases} 3(y - 1)^2 & 0 \le y \le 1 \\ 0 & \text{otherwise} \end{cases}$} is a valid probability density function. 

    \begin{enumerate}
        \item $3 > 0$ and $(y - 1)^2 \ge 0$. Thus, $f(y) = 3(y - 1)^2 \ge 0$. 
        \item $\begin{aligned}[t]
            \int_{-\infty}^\infty f(y) \,dy 
             & = \int_{-\infty}^0 0 \,dy + \int_0^1 3(y - 1)^2 \,dy + \int_1^\infty 0 \,dy \\
             & = 0 + (y - 1) \bigg|_0^1 \\
             & = (1 - 1)^3 - (0 - 1)^3 \\
             & = 1
        \end{aligned}$
    \end{enumerate}
\end{example}

\begin{example}[MMSA Ex. 4.30]
    The response time $X$ in seconds at an online computer terminal, which is the elapsed time between the end of a user's inquiry and the beginning of the system's response, had a distribution given by the following probability density function $$f(x) = \begin{cases} \frac{1}{5}e^{-x/5} & x > 0 \\ 0 & \text{otherwise} \end{cases}$$

    \begin{center}
        \tikzsetnextfilename{c05s01-01}%
        \begin{tikzpicture}
            \draw[thick,->] (-0.2,0) -- (6.2,0) node[right] {$x$};
            \draw[thick,->] (0,-0.2) -- (0,2.7) node[above] {$y$};

            \draw[thick,lightBlue,domain=0:6,smooth] plot ({\x}, {exp(-\x) * 2}) node[above left] {$f(x)$};

            \draw (0.2,2) -- (0,2) node[left] {$\frac{1}{5}$};
        \end{tikzpicture}
    \end{center}

    \begin{enumerate}[label=\alph*)]
        \item What is the probability the response time will be more than $10$ seconds long if there was no response in the first $8$ seconds?

        $\begin{aligned}[t]
            P(X > 10 | x \ge 8) & = P(X > 2)                           \\ 
                                & = \int_2^\infty \frac{1}{5} e^{-x/5} \\
                                & = e^{-\sfrac{2}{5}}                  \\
                                & \approx 67.03 \%
        \end{aligned}$
    \end{enumerate}
\end{example}

\begin{definition}[Expected Value]\index{Expected Value (Continuous RV)}
    The \term{expected value} (sometimes called the \term{mean}) of a continuous random variable $X$ with probability density function $f(x)$ is given by $$E(X) = \int_{-\infty}^\infty x \cdot f(x) \,dx$$ 

    For any real-valued function $g(X)$ of $X$, $$E(g(X)) = \int_{-\infty}^\infty g(x) f(x) \,dx$$
\end{definition}

\begin{definition}[Variance]\index{Variance (Continuous RV)}
    The \term{varianc} of a continuous random variable $X$ with probability density function $f(x)$ is given by $$V(X) = E((X - \mu)^2) = \int_{-\infty}^\infty (x - \mu)^2 f(x) \,dx$$ 

    As was shown in the discrete case, we have an alternative, often shorter way to compute variance: $$V(X) = E(X^2) - E(X)^2$$
\end{definition}

\begin{itemize}
    \item The variance is the average \itblue{squared} deviation of $X$ from its mean.
    \item The \term{standard deviation} of a random variable is the square root of the variance ($SD = \sqrt{V(X)}$).
\end{itemize}

\begin{example}
    A gas station operates a pump that can pump up to $20,000$ gallons of gas a month. The total amount of gas that is pumped at a station in a month can be modelled with a random variable $G$ (measured in $10,000$ gallons) with PDF $$f(g) = \begin{cases} g & 0 < g < 1 \\ 2 - g & 1 \le g < 2 \\ 0 & \text{otherwise} \end{cases}$$

    \begin{enumerate}[label=\alph*)]
        \item Find the expected number of gallons of gas pumped per month.
        
        $\begin{aligned}[t]
            E(F) & = \int_{-\infty}^\infty g \cdot f(g) \,dg \\
            & = \int_0^1 g \cdot g \,dg + \int_1^2 g(2 - g) \,dg \\
            & = \frac{1}{3} g^3 \bigg|_0^1 + \left( g^2 - \frac{1}{3}g^3 \right) \bigg|_1^2 \\
            & = \frac{1}{3} + \left( \left( 4 - \frac{8}{3} \right) - \left( 1 - \frac{1}{3} \right) \right) \\
            & = 3 - \frac{6}{3} \\
            & = 1
        \end{aligned}$

        \item Find the variance in the number of gallons of gas pumped per month.
        
        $\begin{aligned}[t]
            V(G) & = E((G - \mu)^2) \\
                 & = E(G^2) - E(G)^2 \\
        \end{aligned}$

        Note that $\begin{aligned}[t]
            E(G^2) & = \int_{-\infty}^\infty g^2 \cdot f(g) \,dg \\
            & = \int_0^1 g^2 \cdot g \,dg + \int_1^2 g^2 (2 - g) \,dg
        \end{aligned}$
    \end{enumerate}
\end{example}

\section{Common Continuous Distributions}

\subsection{Uniform Distribution}

The previous example uses a common continuous distribution called the `\term{Uniform Distribution}'. A distribution with constant density tells us that any intervals of the same width in the support have equal probability of occurrence. Such distributions are called \bred{uniform}.

\begin{definition}[Uniform Distribution]\index{Uniform Distribution}
    A continuous random variable $X$ follows a \term{uniform distribution} on the interval $a \le X \le b$ if it has probability density function $$f(x) = \begin{cases} \frac{1}{b - a} & a \le x \le b \\ 0 & \text{otherwise} \end{cases}$$ 
    
    A uniform distribution has mean and variance defined by its endpoints $$E(X) = \frac{b + a}{2} \qquad \qquad V(X) = \frac{(b - a)^2}{12}$$
\end{definition}

\subsection{Cumulative Distribution Function}

\begin{definition}[Cumulative Distribution Function]\index{Cumulative Distribution Function}
    The \term{cumulative distribution function} (CDF) of a continuous random variable $X$ is the function $F(x)$ that returns the cumulative probability of a random variable $X$ for any value $x \in \mathbb{R}$ $$F(x) = P(X \le x)$$

    The function $F(x)$ can be explicitly found by finding an expression for $\int_{-\infty}^x f(w)$

    The derivative of the CDF $F'(x)$ is the PDF of $X$: $F'(x) = F(x)$
\end{definition}

\begin{proposition}[Properties of CDF]
    Below are some properties of CDF. 

    \begin{itemize}
        \item $P(X = c) = \int_c^c f(x)\,dx = 0 \implies P(X \le c) = P(X < c)$
        \item $P(a \le X \le b) = \int_a^b f(x) \,dx = F(b) - F(a)$
        \item $\lim_{x\to\infty} F(x) = 1$ and $\lim_{x\to-\infty} F(x) = 0$
    \end{itemize}
\end{proposition}

\begin{example}
    The distribution function of a random variable $X$ is as follows: $$F(x) = \begin{cases} 0 & x < 0 \\ \frac{x^3}{2} & 0 \le x < 1 \\ \frac{x}{2} & 1 \le x \le 2 \\ 1 & x > 2 \end{cases}$$ Find $P(0.5 \le X \le 1.5)$.

    %TODO: refer to lec slides
\end{example}

\begin{example}
    For a random variable $Y$ with probability density function $f(y) = 3(y - 1)^2$, $0 \le y \le 1$

    \begin{enumerate}[label=\alph*)]
        \item Sketch the PDF.

        \begin{center}
            \begin{tikzpicture}
                %\draw[domain=0:1] plot ();
            \end{tikzpicture}
        \end{center}
        
        %TODO: draw it
        
        \item Find the cumulative distribution function of $Y$.
        
        CDF of $Y$: $P(Y \le y)$

        For $y \in [0, 1)$, $\begin{aligned}[t]
            P(Y \le y) & = \int_0^y 3(u - 1)^2 \,du \\
                       & = (u - 1)^3 \bigg|_0^y \\
                       & = (y - 1)^2 - (0 - 1)^3 \\
                       & = 1 + (y - 1)^3
        \end{aligned}$

        Thus, we have $F_Y(y) = \begin{cases} 0 & y < 0 \\ 1 + (y - 1)^3 & 0 \le y < 1 \\ 1 & y \ge 1 \end{cases}$

        %TODO: see slides
    \end{enumerate}
\end{example}

% TODO: exponential distribution (see slides)

\begin{example}
    Previously, we modeled the number of shiba arrivals at the dog park over a day by a Poisson distribution. Suppose on average there are $5$ Shiba arrivals per day.

    \begin{enumerate}[label=\alph*)]
        \item A Shiba just arrived at the dog park. What is the probability that you'll another one will arrive in the next day (full 24 hours)?
        
        Let $T$ be the number of days until the next Shiba arrival. 

        $\begin{aligned}[t]
            R(T \le 1) & = F_t(1)                                               \\
                       & = \int_0^1 \frac{1}{\theta} e^{-\frac{t}{\theta}} \,dt \\
                       & = 1 - e^{-\frac{1}{\theta}}                            \\
                       & = 1 - e^{-5}                                           \\
                       & \approx 0.9933
        \end{aligned}$

        \item It's been 3 days since you've last seen your a Shiba at the dog park. What's the probability you'll have to wait at least five days before another Shiba arrives at the park?
        
        $\begin{aligned}[t]
            P(T \ge 5 | T \ge 3) & = \frac{P(T \ge 5 \land T \ge 3)}{T \ge 3} \\
                                 & = \frac{P(T \ge 5)}{P(T \ge 3)}
        \end{aligned}$
    \end{enumerate}
\end{example}

\subsection{Gamma Distribution}

We have learned that the exponential distribution models the random interval until the \bred{next} Poisson arrival (or in other words, the random interval between two consecutive arrivals). Can it also be used to model the total interval between any two Poisson arrivals?

What would the distribution of total time between the second and sixth shiba arrival look like? Will it also be exponential? What do you think?

% TODO: see slides

\section{Percentile}

\begin{definition}[Percentile]\index{Percentile}
    The $k$\textsuperscript{th} percentile is the value of a random variable for which $k\%$ of values are less than or equal to it. For a random variable $X$ with PDF $f(x)$, the $k$\textsuperscript{th} percentile $x_{k/100}$ is the value of $X$ at which $k\%$ of outcomes lie below it. That is, $$P(X \le x_{k/100}) = \frac{k}{100} \qquad OR \qquad x_{k/100} = F^{-1} \left( \frac{k}{100} \right)$$
\end{definition}

\textbf{Special Percentiles}

\begin{itemize}
    \item The \term{median} is also called the $50$\textsuperscript{th} percentile
    \item The \term{first quartile} and \term{third quartile} are the $25$\textsuperscript{th} and $75$\textsuperscript{th} percentiles, respectively. 
\end{itemize}

\begin{example}
    Find the median of a random variable $M$ with PDF $f(m) = 3m^2$, $0 \le m < 1$. 

    Let $m_{0.5}$ be the median. 

    $\begin{aligned}[t]
        \int_{0}^{m_{0.5}} 3m^2 \,dm & = 0.5           \\
        m^3 \bigg|_{0}^{m_{0.5}}     & = 0.5           \\
        {m_{0.5}}^3                  & = 0.5           \\
        m_{0.5}                      & = \sqrt[3]{0.5} \\
                                     & \approx 0.79
    \end{aligned}$
\end{example}

